{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Fundamental engineering practices\n",
    "\n",
    "Writing computer code is only a fraction of software engineering.  A large chunk of efforts is spent in the coding infrastructure.  The keyword of making the engineering system is automation.\n",
    "\n",
    "1. Automation\n",
    "   1. Bash scripting\n",
    "   2. Makefile\n",
    "   3. Cmake (cross-platform, multi-language automation)\n",
    "2. Version control and regression\n",
    "   1. Git version control system\n",
    "   2. Automatic testing: author and run with google-test and py.test\n",
    "   3. Wrap to Python and test there: pybind11\n",
    "   4. Continuous integration to avoid regression\n",
    "3. Work that cannot be automated\n",
    "   1. Code review (use github for demonstration)\n",
    "   2. Timing to debug for performance\n",
    "      1. Wall time and CPU cycles\n",
    "      2. System time and user time\n",
    "      3. Python timing tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Bash scripting\n",
    "\n",
    "Shell script is the most common way for automation.  A shell is responsible for taking commands from users.  Every operating system provides shells.  Because of the ubiqitous Linux, `bash` becomes the most popular shell.  A bash shell script should work on almost all computer systems.\n",
    "\n",
    "Here I'll introduce some useful tricks for scripting bash."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Overview\n",
    "\n",
    "Structure of a simplest script:\n",
    "\n",
    "1. Shebang.\n",
    "2. Comment/document.\n",
    "3. Setup.\n",
    "4. Action."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Example (`clone-python.sh`):\n",
    "\n",
    "```bash\n",
    "#!/bin/bash\n",
    "#\n",
    "# This script clones the cpython repository.\n",
    "\n",
    "# setup environment variables.\n",
    "root=${ROOT:-~/tmp}\n",
    "pkgname=python\n",
    "pkgbranch=${VERSION:-3.7}\n",
    "pkgfull=$pkgname-$pkgbranch\n",
    "pkgrepo=https://github.com/python/cpython.git\n",
    "\n",
    "# clone.\n",
    "mkdir -p $root\n",
    "cd $root\n",
    "echo `pwd`\n",
    "if [ ! -d $pkgfull ] ; then\n",
    "  git clone -q -b $pkgbranch $pkgrepo $pkgfull\n",
    "fi\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A shell script file contains commands to `bash`.  Executing the bash script file is almost the same as typing those commands directly in an interactive shell.  Bash shell scripts are the most common way to record the commands and automate the work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables are essential in programming langauges.  Variables in bash do not have types, but there are two kinds of variables distinguished by their scopes.  One is the _shell variable_, which lives in the current shell.  The other is the _environment variable_, which is also visible in child processes.\n",
    "\n",
    "```bash\n",
    "shell_var=\"shell_value\"\n",
    "\n",
    "env_var=\"env_value\"\n",
    "export env_var\n",
    "export env_var2=\"other_env_value\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Default value when variable isn't set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no such thing\r\n"
     ]
    }
   ],
   "source": [
    "# show the fallback value since the variable isn't set\n",
    "!unset THISENVVAR; echo ${THISENVVAR:-no such thing}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some value\r\n"
     ]
    }
   ],
   "source": [
    "# use the variable value\n",
    "!THISENVVAR=\"some value\"; echo ${THISENVVAR:-no such thing}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Sub-process vs source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bash script may be run in two ways.  One is to run it like an ordinary program.  A new process will be created by the current shell, and the script will be run in that process.  The other way is to use `source` (or its POSIX-compatible synonym, `.`) to run it in the current shell.  The latter makes the shell script work like a replay of the command sequence in it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Assume we have a bash script called `dosomething.sh`:\n",
    "\n",
    "```bash\n",
    "#!/bin/bash\n",
    "export MYENVVAR=\"MYENVVAR is set to what I want\"\n",
    "echo \"do something\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable isn't set in the calling shell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do something\r\n",
      "MYENVVAR is not set\r\n"
     ]
    }
   ],
   "source": [
    "!unset MYENVVAR; ./dosomething.sh; echo ${MYENVVAR:-\"MYENVVAR is not set\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable gets exported to the calling shell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do something\r\n",
      "MYENVVAR is set to what I want\r\n"
     ]
    }
   ],
   "source": [
    "!unset MYENVVAR; source ./dosomething.sh; echo ${MYENVVAR:-\"MYENVVAR is not set\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Redirection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When executing a command in a bash script it's commonplace to redirect the output to a file or another command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a line output\r\n"
     ]
    }
   ],
   "source": [
    "!echo \"a line output\" > line.log ; cat line.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes we want to redirect both stdout and stderr to a file.  The idiom is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a line output\r\n"
     ]
    }
   ],
   "source": [
    "!echo \"a line output\" > line.log 2>&1 ; cat line.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `2>&1` should be written after `> line.log`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp: nothisfile.txt: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!cp nothisfile.txt another.txt 2>&1 > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp nothisfile.txt another.txt > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may redirect only the standard error to null device.  It is often used to capture the stdout result to a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grep: bind1: Is a directory\r\n",
      "grep: build: Is a directory\r\n",
      "grep: gtest: Is a directory\r\n",
      "grep: make1: Is a directory\r\n",
      "grep: make2: Is a directory\r\n",
      "grep: make3: Is a directory\r\n",
      "grep: make4: Is a directory\r\n",
      "grep: nsd: Is a directory\r\n",
      "grep: repo1: Is a directory\r\n",
      "engineering.ipynb: \"!var=$(grep impossiblestring *) ; echo $var\" engineering.ipynb: \"!var=$(grep impossiblestring bashfunction.sh bind1 bisection.png build dosomething.sh engineering.ipynb engineering_bare.ipynb gitdistribution.png gitgraph.png gitsync.png gtest line.log line1.log line2.log make1 make2 make3 make4 nsd repo1 shownp.sh 2> /dev/null) ; echo $var\" engineering_bare.ipynb: \"!var=$(grep impossiblestring *) ; echo $var\" engineering_bare.ipynb: \"!var=$(grep impossiblestring bashfunction.sh bind1 bisection.png build dosomething.sh engineering.ipynb engineering_bare.ipynb gitdistribution.png gitgraph.png gitsync.png gtest line.log line1.log line2.log make1 make2 make3 make4 nsd repo1 shownp.sh 2> /dev/null) ; echo $var\"\r\n"
     ]
    }
   ],
   "source": [
    "# without redirecting stderr we see unwanted messages\n",
    "!var=$(grep impossiblestring *) ; echo $var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "engineering.ipynb: \"!var=$(grep impossiblestring *) ; echo $var\" engineering.ipynb: \"!var=$(grep impossiblestring bashfunction.sh bind1 bisection.png build dosomething.sh engineering.ipynb engineering_bare.ipynb gitdistribution.png gitgraph.png gitsync.png gtest line.log line1.log line2.log make1 make2 make3 make4 nsd repo1 shownp.sh 2> /dev/null) ; echo $var\" engineering_bare.ipynb: \"!var=$(grep impossiblestring *) ; echo $var\" engineering_bare.ipynb: \"!var=$(grep impossiblestring bashfunction.sh bind1 bisection.png build dosomething.sh engineering.ipynb engineering_bare.ipynb gitdistribution.png gitgraph.png gitsync.png gtest line.log line1.log line2.log make1 make2 make3 make4 nsd repo1 shownp.sh 2> /dev/null) ; echo $var\"\r\n"
     ]
    }
   ],
   "source": [
    "# throw stderr to null device and we get only the wanted information\n",
    "!var=$(grep impossiblestring * 2> /dev/null) ; echo $var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Branching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To write smart scripts we need the `if`-`else` branching construct.  The following example detects the OS and runs different commands to obtain the number of (logical) processors on the machine:\n",
    "\n",
    "```bash\n",
    "#!/bin/bash\n",
    "if [[ \"$(uname)\" == \"Darwin\" ]] ; then\n",
    "  NP=${NP:-$(sysctl -n hw.ncpu)}\n",
    "elif [[ \"$(uname)\" == \"Linux\" ]] ; then\n",
    "  NP=${NP:-$(cat /proc/cpuinfo | grep processor | wc -l)}\n",
    "else\n",
    "  NP=${NP:=1}\n",
    "fi\n",
    "echo \"NP may be set to $NP\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Darwin\r\n",
      "NP may be set to 8\r\n"
     ]
    }
   ],
   "source": [
    "!uname; ./shownp.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Function\n",
    "\n",
    "`bash` allows us to write functions to collect commands and rerun it over and over in a script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "#!/bin/bash\n",
    "runcmd () {\n",
    "  echo \"run command: ${@:2}\"\n",
    "  { time \"${@:2}\" ; } > $1 2>&1\n",
    "  echo \"done; log file: $(cd \"$(dirname $1)\" && pwd)/$1\"\n",
    "}\n",
    "runcmd line1.log echo \"first command\"\n",
    "runcmd line2.log echo \"second command\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run command: echo first command\r\n",
      "done; log file: /Users/yungyuc/hack/code/nsd/notebook/20sp_nctu/02_engineering/line1.log\r\n",
      "run command: echo second command\r\n",
      "done; log file: /Users/yungyuc/hack/code/nsd/notebook/20sp_nctu/02_engineering/line2.log\r\n",
      "first command\r\n",
      "\r\n",
      "real\t0m0.001s\r\n",
      "user\t0m0.000s\r\n",
      "sys\t0m0.000s\r\n",
      "second command\r\n",
      "\r\n",
      "real\t0m0.000s\r\n",
      "user\t0m0.000s\r\n",
      "sys\t0m0.000s\r\n"
     ]
    }
   ],
   "source": [
    "!./bashfunction.sh ; cat line1.log; cat line2.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Makefile\n",
    "\n",
    "`Makefile` is the input file of a tool called `make`.  `make` has many derived implementations since its creation in 1976 at Bell Labs.  The most popular implementation is GNU `make`, which is also required in building the Linux kernel.  We will be focusing on GNU `make`.\n",
    "\n",
    "A Makefile consists of rules in the following format:\n",
    "\n",
    "```make\n",
    "target : prerequisites [...]\n",
    "        recipe (1)\n",
    "        recipe (2)\n",
    "        ...\n",
    "```\n",
    "\n",
    "Note a tab is **required** at the beginning of each recipe line.  And rules and recipes are line-based.  If a recipe should use a single line and no more, or it needs to use `\\` for line continuation.  So is the rule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## `make`: Automating Your Recipes\n",
    "\n",
    "`make` keeps track of the file timestamps.\n",
    "* If the source file is older than its object file, `make` knows that it doesn't need to invoke the compiler.\n",
    "* If, in the other way around, the source file is newer than its object file, or the executable is newer than the object and library file, `make` will run the building tools according to the recipes written in the `Makefile`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "> Make originated with a visit from Steve Johnson (author of yacc, etc.), storming into my office, cursing the Fates that had caused him to waste a morning debugging a correct program (bug had been fixed, file hadn't been compiled, cc \\*.o was therefore unaffected). As I had spent a part of the previous evening coping with the same disaster on a project I was working on, the idea of a tool to solve it came up. It began with an elaborate idea of a dependency analyzer, boiled down to something much simpler, and turned into Make that weekend. Use of tools that were still wet was part of the culture. Makefiles were text files, not magically encoded binaries, because that was the Unix ethos: printable, debuggable, understandable stuff.\n",
    ">\n",
    "> _Stuart Feldman_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Makefile format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Use the simple hello world program as an example for writing a make file.  First we set a variable `CXX` to designate the compiler command to be used:\n",
    "\n",
    "```\n",
    "CXX = g++\n",
    "```\n",
    "\n",
    "Write the first rule for linking the executable.  The first rule is the default rule that `make` will use when it is invoked without a target.\n",
    "\n",
    "```\n",
    "hello: hello.o hellomain.o\n",
    "\t$(CXX) hello.o hellomain.o -o hello\n",
    "```\n",
    "\n",
    "Then write two rules for the object files.  First `hello.o`:\n",
    "\n",
    "```\n",
    "hello.o: hello.cpp hello.hpp\n",
    "\t$(CXX) -c hello.cpp -o hello.o\n",
    "```\n",
    "\n",
    "Second `hellomain.o`:\n",
    "\n",
    "```\n",
    "hellomain.o: hellomain.cpp hello.hpp\n",
    "\t$(CXX) -c hellomain.cpp -o hellomain.o\n",
    "```\n",
    "\n",
    "Now we can use a single command to run all the recipes for building `hello`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g++ -c hello.cpp -o hello.o\n",
      "g++ -c hellomain.cpp -o hellomain.o\n",
      "g++ hello.o hellomain.o -o hello\n"
     ]
    }
   ],
   "source": [
    "!cd make1; rm -f hello *.o; make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`make` the second time.  Nothing needs to be done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make: `hello' is up to date.\r\n"
     ]
    }
   ],
   "source": [
    "!cd make1; make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we change one of the source files (say, `hello.cpp`), `make` knows from the prerequisites (dependencies) that the other one doesn't need to be rebuilt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g++ -c hello.cpp -o hello.o\n",
      "g++ hello.o hellomain.o -o hello\n"
     ]
    }
   ],
   "source": [
    "!cd make1; touch hello.cpp; make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the shared prerequisites (the header file `hello.hpp`).  Everything needs to be rebuilt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g++ -c hellomain.cpp -o hellomain.o\r\n"
     ]
    }
   ],
   "source": [
    "!cd make1; touch hello.hpp; make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Automatic variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found some duplicated file names in the recipes in the above example.  `make` provides _automatic variables_ that allow us to remove them.\n",
    "\n",
    "* `$@` is the file name of the target of the rule.\n",
    "* `$^` is the file names of all the prerequisites.\n",
    "* `$<` is the file name of the first prerequisite.\n",
    "\n",
    "Aided by the automatic variables, we can simplify the recipes:\n",
    "\n",
    "```\n",
    "hello: hello.o hellomain.o\n",
    "\t$(CXX) $^ -o $@\n",
    "\n",
    "hello.o: hello.cpp hello.hpp\n",
    "\t$(CXX) -c $< -o $@\n",
    "\n",
    "hellomain.o: hellomain.cpp hello.hpp\n",
    "\t$(CXX) -c $< -o $@\n",
    "```\n",
    "\n",
    "The new `Makefile` works exactly the same as the previous one, but doesn't have the duplicated file names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g++ -c hello.cpp -o hello.o\n",
      "g++ -c hellomain.cpp -o hellomain.o\n",
      "g++ hello.o hellomain.o -o hello\n"
     ]
    }
   ],
   "source": [
    "!cd make2; rm -f hello *.o; make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Implicit rule\n",
    "\n",
    "Even with the automatic variable, we see duplicated recipes for the two object file targets.  It can be removed by rewriting the *implicit rule* for `.o` file:\n",
    "\n",
    "```\n",
    "%.o: %.cpp hello.hpp\n",
    "\t$(CXX) -c $< -o $@\n",
    "```\n",
    "\n",
    "`%` in the target will match any non-empty characters, and it is expanded in the prerequisite.  Thus, the `Makefile` will become much simpler.  And there's fewer places for mistakes:\n",
    "\n",
    "```\n",
    "CXX = g++\n",
    "\n",
    "hello: hello.o hellomain.o\n",
    "\t$(CXX) $^ -o $@\n",
    "\n",
    "%.o: %.cpp hello.hpp\n",
    "\t$(CXX) -c $< -o $@\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g++ -c hello.cpp -o hello.o\n",
      "g++ -c hellomain.cpp -o hellomain.o\n",
      "g++ hello.o hellomain.o -o hello\n"
     ]
    }
   ],
   "source": [
    "!cd make3; rm -f hello *.o; make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Popular phony target\n",
    "\n",
    "It is handy to have some targets that are not files, and use them to accomplish some pre-defined operations.  For example, almost all practical `Makefile`\\ s has a target called `clean`, and it removes all the built files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf hello *.o\r\n"
     ]
    }
   ],
   "source": [
    "!cd make4; make clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These targets are called _phony targets_ (not real files).  The above operation is accomplished by the following rule:\n",
    "\n",
    "```\n",
    ".PHONY: clean\n",
    "clean:\n",
    "\trm -rf hello *.o\n",
    "```\n",
    "\n",
    "Another common use of phony targets is to redirect the default rule:\n",
    "\n",
    "```\n",
    "# If the following two lines are commented out, the default target becomes hello.o.\n",
    ".PHONY: default\n",
    "default: hello\n",
    "\n",
    "# Implicit rules will be skipped when searching for default.\n",
    "#%.o: %.cpp hello.hpp\n",
    "#\t$(CXX) -c $< -o $@\n",
    "\n",
    "hello.o: hello.cpp hello.hpp\n",
    "\t$(CXX) -c $< -o $@\n",
    "\n",
    "hellomain.o: hellomain.cpp hello.hpp\n",
    "\t$(CXX) -c $< -o $@\n",
    "\n",
    "hello: hello.o hellomain.o\n",
    "\t$(CXX) $^ -o $@\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf hello *.o\n",
      "g++ -c hello.cpp -o hello.o\n",
      "g++ -c hellomain.cpp -o hellomain.o\n",
      "g++ hello.o hellomain.o -o hello\n"
     ]
    }
   ],
   "source": [
    "!cd make4; make clean; make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Cmake\n",
    "\n",
    "Automation is needed to simplify entangled operations which induce human errors.  Cross-platform building is a common example of such operations.  We've seen in a previous example (a bash shell script) how it comes to us:\n",
    "\n",
    "```\n",
    "#!/bin/bash\n",
    "if [[ \"$(uname)\" == \"Darwin\" ]] ; then\n",
    "  NP=${NP:-$(sysctl -n hw.ncpu)}\n",
    "elif [[ \"$(uname)\" == \"Linux\" ]] ; then\n",
    "  NP=${NP:-$(cat /proc/cpuinfo | grep processor | wc -l)}\n",
    "else\n",
    "  NP=${NP:=1}\n",
    "fi\n",
    "echo \"NP may be set to $NP\"\n",
    "```\n",
    "\n",
    "As the software grows, such simple conditional statements fail to handle the complexity.  It applies to both shell scripts and make files.  We need a dedicated tool for orchestrating the build processs.  Cmake is such a tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Although it has \"make\" in the name, cmake is _not_ a variant of make.  It requires its own configuration file, called `CMakeLists.txt`.  On Linux, we usually let cmake to generate GNU make files, and then run make to build the software.  This is a so-called two-stage building process.  Cmake provides many helpers so that we may relatively easily configure the real build commands to deal with compiler flags, library and executable file names, and third-party librarires (dependencies).\n",
    "\n",
    "It is easy to let cmake use a separate build directory (it's the default behavior); the built files will be in a different directory from the source tree.  In this way, a single source tree may easily produce multiple binary trees.\n",
    "\n",
    "Since cmake is only used to deal with complex configuration, we may not use a simple example to show how it is used.  Instead, high-level information about what it does will be provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## How to run cmake\n",
    "\n",
    "By default cmake expects to be run in a separate build directory.  Assume the current working directory is the project root.  The common way to invoke cmake for building the project is:\n",
    "\n",
    "```\n",
    "$ mkdir -p build/dev\n",
    "$ cd build/dev\n",
    "$ cmake ../.. -DCMAKE_BUILD_TYPE=Release\n",
    "-- The C compiler identification is AppleClang 10.0.1.10010046\n",
    "-- The CXX compiler identification is AppleClang 10.0.1.10010046\n",
    "...\n",
    "-- Configuring done\n",
    "-- Generating done\n",
    "-- Build files have been written to: /absolute/path/to/build/dev\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Select C++ standards\n",
    "\n",
    "We may use cmake to pick which standard the C++ compiler should use:\n",
    "\n",
    "```\n",
    "set(CMAKE_CXX_STANDARD 14)\n",
    "set(CMAKE_CXX_STANDARD_REQUIRED ON)\n",
    "```\n",
    "\n",
    "Different compilers may have different options for the C++ standard.  clang and gcc use `-std=`, while msvc uses `/std:`.  The cmake variables know what to use for each of the supported compilers.  The generated make file will result in a recipe like:\n",
    "\n",
    "```\n",
    "c++ -O3 -DNDEBUG -fPIC -flto -std=c++14 -o CMakeFiles/_libst.dir/src/python/libst.cpp.o -c /absolute/path/to/src/python/libst.cpp\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Add a custom option\n",
    "\n",
    "Cmake allows to add any custom option that is consumed from the command line.  For example, a new `DEBUG_SYMBOL` optiona can be added by the following cmake list code:\n",
    "\n",
    "```\n",
    "option(DEBUG_SYMBOL \"add debug information\" ON)\n",
    "\n",
    "if(DEBUG_SYMBOL)\n",
    "    set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -g\")\n",
    "endif()\n",
    "```\n",
    "\n",
    "The option is supplied to cmake as such:\n",
    "\n",
    "```\n",
    "cmake root -DDEBUG_SYMBOL=ON\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Git version control system\n",
    "\n",
    "Version control system (VCS), which is also called source control managerment (SCM), is essential for programmers to engineer software.  There are only two things that programmers may engineer: the contents in source files, and the locations of them.  VCS is to tool to track their changes.\n",
    "\n",
    "Git (https://git-scm.com) is a popular VCS.  Created in 2005, it's a fairly young tool, while the history of VCS is at least 3 decades.  There are other tools for version control, but the popularity of git makes it a right tool for most scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Github\n",
    "\n",
    "Github (https://github.com) is a service tightly related to git.  It is a hosting service for git repositories.  A repository is the basic unit for a software project that is controlled with git.  Most of the time, a git-controlled project is equivalent to a git repository.  Github allows you to upload repositories and share them with others.  You may make the repository public (to the world) or private (accessible by only selected accounts)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Create a repository\n",
    "\n",
    "The way git keeps track of the version is to store the differences into a graph.  The graph is directed and acyclic, like the following diagram:\n",
    "\n",
    "<img src=\"gitgraph.png\" style=\"width: 80%; text-align: center;\">\n",
    "\n",
    "Each of the circle is called a changeset, or simply change.  Each changeset stores the difference of all the files in a repository.  The difference is also called diff or patch.\n",
    "\n",
    "The first step to use git is to create the graph database, i.e., the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "!rm -rf repo1 # Reset working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized empty Git repository in /Users/yungyuc/hack/code/nsd/notebook/20sp_nctu/02_engineering/repo1/.git/\r\n"
     ]
    }
   ],
   "source": [
    "# Create a brand new repository.\n",
    "!git init repo1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: your current branch 'master' does not have any commits yet\r\n"
     ]
    }
   ],
   "source": [
    "# The repository is empty.\n",
    "!cd repo1 ; git log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Add a file and commit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"This is a new repository\" > repo1/README\n",
    "!cd repo1 ; git add README"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master (root-commit) a5493c8] Initialize the repository\r\n",
      " 1 file changed, 1 insertion(+)\r\n",
      " create mode 100644 README\r\n"
     ]
    }
   ],
   "source": [
    "!cd repo1 ; git commit -m \"Initialize the repository\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* \u001b[31ma5493c8\t\u001b[32m (HEAD -> master)\u001b[0m Initialize the repository"
     ]
    }
   ],
   "source": [
    "!cd repo1 ; git log --graph --pretty=format:%x1b[31m%h%x09%x1b[32m%d%x1b[0m%x20%s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we saved to the git repository is a changeset.  A git repository is a database consist of a graph dd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Add more changes\n",
    "\n",
    "We may add more files to the repository.  If there's only one programmer, it's common that our history will be a straight line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master 97142fc] Add code\n",
      " 4 files changed, 28 insertions(+)\n",
      " create mode 100644 Makefile\n",
      " create mode 100644 hello.cpp\n",
      " create mode 100644 hello.hpp\n",
      " create mode 100644 hellomain.cpp\n",
      "[master 488c712] Change code; first time\n",
      " 1 file changed, 3 insertions(+), 3 deletions(-)\n",
      "[master 0758923] Change code; second time\n",
      " 1 file changed, 1 insertion(+), 4 deletions(-)\n",
      "[master 5baf2fb] Change code; last time\n",
      " 1 file changed, 17 insertions(+), 2 deletions(-)\n"
     ]
    }
   ],
   "source": [
    "!cp make1/*.cpp make1/*.hpp make1/Makefile repo1\n",
    "!cd repo1 ; git add * ; git commit -m \"Add code\"\n",
    "!cp make2/*.cpp make2/*.hpp make2/Makefile repo1\n",
    "!cd repo1 ; git add * ; git commit -m \"Change code; first time\"\n",
    "!cp make3/*.cpp make3/*.hpp make3/Makefile repo1\n",
    "!cd repo1 ; git add * ; git commit -m \"Change code; second time\"\n",
    "!cp make4/*.cpp make4/*.hpp make4/Makefile repo1\n",
    "!cd repo1 ; git add * ; git commit -m \"Change code; last time\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* \u001b[31m5baf2fb\t\u001b[32m (HEAD -> master)\u001b[0m Change code; last time\r\n",
      "* \u001b[31m0758923\t\u001b[32m\u001b[0m Change code; second time\r\n",
      "* \u001b[31m488c712\t\u001b[32m\u001b[0m Change code; first time\r\n",
      "* \u001b[31m97142fc\t\u001b[32m\u001b[0m Add code\r\n",
      "* \u001b[31ma5493c8\t\u001b[32m\u001b[0m Initialize the repository"
     ]
    }
   ],
   "source": [
    "# After adding more changes, show how the history looks.\n",
    "!cd repo1 ; git log --graph --pretty=format:%x1b[31m%h%x09%x1b[32m%d%x1b[0m%x20%s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Show differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mdiff --git a/Makefile b/Makefile\u001b[m\r\n",
      "\u001b[1mindex 596e595..81a3d63 100644\u001b[m\r\n",
      "\u001b[1m--- a/Makefile\u001b[m\r\n",
      "\u001b[1m+++ b/Makefile\u001b[m\r\n",
      "\u001b[36m@@ -1,9 +1,24 @@\u001b[m\r\n",
      " CXX = g++\u001b[m\r\n",
      " \u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m# If the following two lines are commented out, the default target becomes hello.o.\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m.PHONY: default\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32mdefault: hello\u001b[m\r\n",
      "\u001b[32m+\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m# Implicit rules will be skipped when searching for default.\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m#%.o: %.cpp hello.hpp\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m#\t$(CXX) -c $< -o $@\u001b[m\r\n",
      "\u001b[32m+\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32mhello.o: hello.cpp hello.hpp\u001b[m\r\n",
      "\u001b[32m+\u001b[m\t\u001b[32m$(CXX) -c $< -o $@\u001b[m\r\n",
      "\u001b[32m+\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32mhellomain.o: hellomain.cpp hello.hpp\u001b[m\r\n",
      "\u001b[32m+\u001b[m\t\u001b[32m$(CXX) -c $< -o $@\u001b[m\r\n",
      "\u001b[32m+\u001b[m\r\n",
      " hello: hello.o hellomain.o\u001b[m\r\n",
      " \t$(CXX) $^ -o $@\u001b[m\r\n",
      " \u001b[m\r\n",
      "\u001b[31m-%.o: %.cpp hello.hpp\u001b[m\r\n",
      "\u001b[31m-\t$(CXX) -c $< -o $@\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m.PHONY: clean\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32mclean:\u001b[m\r\n",
      "\u001b[32m+\u001b[m\t\u001b[32mrm -rf hello *.o\u001b[m\r\n",
      " \u001b[m\r\n",
      " # vim: set noet nobomb fenc=utf8 ff=unix:\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!cd repo1 ; git diff HEAD~1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mdiff --git a/Makefile b/Makefile\u001b[m\r\n",
      "\u001b[1mindex 596e595..a55350c 100644\u001b[m\r\n",
      "\u001b[1m--- a/Makefile\u001b[m\r\n",
      "\u001b[1m+++ b/Makefile\u001b[m\r\n",
      "\u001b[36m@@ -3,7 +3,10 @@\u001b[m \u001b[mCXX = g++\u001b[m\r\n",
      " hello: hello.o hellomain.o\u001b[m\r\n",
      " \t$(CXX) $^ -o $@\u001b[m\r\n",
      " \u001b[m\r\n",
      "\u001b[31m-%.o: %.cpp hello.hpp\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32mhello.o: hello.cpp hello.hpp\u001b[m\r\n",
      "\u001b[32m+\u001b[m\t\u001b[32m$(CXX) -c $< -o $@\u001b[m\r\n",
      "\u001b[32m+\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32mhellomain.o: hellomain.cpp hello.hpp\u001b[m\r\n",
      " \t$(CXX) -c $< -o $@\u001b[m\r\n",
      " \u001b[m\r\n",
      " # vim: set noet nobomb fenc=utf8 ff=unix:\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!cd repo1 ; git diff HEAD~1 HEAD~2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Clone\n",
    "\n",
    "Git is a distributed VCS.  It means that when we use git to track history, we don't need to rely on a remote server.  The way git does it is to make every location that needs the history to have a full copy of it.  When we develop code and add patches to the repository, we don't need to talk to a server.\n",
    "\n",
    "In a collaborative environment, we usually have an \"origin\", or \"blessed\" repository.  It is where we get the authentic history.  Then it is _cloned_ to our workstation, where we do software development.  After we make the necessary changes and check in to the (local) repository, we synchronize to the remote repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"gitdistribution.png\" style=\"width: 80%; text-align: center;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'nsd' already exists and is not an empty directory.\r\n"
     ]
    }
   ],
   "source": [
    "# Try to clone a repository from github.\n",
    "!git clone git@github.com:yungyuc/nsd.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Synchronization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The synchronization is two-way: _push_ means to upload the local changes to the remote repository, and _pull_ downloads changes in the remote repository to local.  Git is reponsible for making sure to have no duplication of changes.\n",
    "\n",
    "<img src=\"gitsync.png\" style=\"width: 80%; text-align: center;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Branching and merging\n",
    "\n",
    "<img src=\"https://nvie.com/img/git-model@2x.png\" style=\"width: 560px; text-align: center;\">\n",
    "\n",
    "[A successful Git branching model, Vincent Driessen, 2010](https://nvie.com/posts/a-successful-git-branching-model/)\n",
    "\n",
    "In addition to branching and merging, rebasing is also a critical technique for operating a git repository, but it is best to learn it by yourself when developing code in this course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Bisecting\n",
    "\n",
    "With the clear history in a repository, when we have a bug in a system, it becomes relatively easy to hunt down when and how the problem is introduced by bisection.\n",
    "\n",
    "<img src=\"bisection.png\" style=\"width: 90%; text-align: center;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Automatic testing\n",
    "\n",
    "Automatic testing is part of software development flow.  When working on a project, we may first build the code:\n",
    "\n",
    "```\n",
    "$ mkdir -p build/dev\n",
    "$ pushd build/dev\n",
    "$ cmake ../.. -DCMAKE_BUILD_TYPE=Release\n",
    "...\n",
    "$ popd\n",
    "$ make -C build/dev\n",
    "...\n",
    "```\n",
    "\n",
    "Then make some modification:\n",
    "\n",
    "```\n",
    "$ vi include/spacetime.hpp\n",
    "...\n",
    "```\n",
    "\n",
    "Rebuild:\n",
    "\n",
    "```\n",
    "$ make -C build/dev\n",
    "...\n",
    "```\n",
    "\n",
    "After the building succeeds, run testing code included in the project to make sure the code we added didn't break the system:\n",
    "\n",
    "```\n",
    "$ ./build/dev/gtests/libst_gtests\n",
    "[==========] Running 3 tests from 2 test cases.\n",
    "[----------] Global test environment set-up.\n",
    "[----------] 2 tests from CopyTest\n",
    "[ RUN      ] CopyTest.Grid\n",
    "[       OK ] CopyTest.Grid (0 ms)\n",
    "[ RUN      ] CopyTest.Solver\n",
    "[       OK ] CopyTest.Solver (0 ms)\n",
    "[----------] 2 tests from CopyTest (0 ms total)\n",
    "\n",
    "[----------] 1 test from SolverTest\n",
    "[ RUN      ] SolverTest.Celm\n",
    "[       OK ] SolverTest.Celm (0 ms)\n",
    "[----------] 1 test from SolverTest (0 ms total)\n",
    "\n",
    "[----------] Global test environment tear-down\n",
    "[==========] 3 tests from 2 test cases ran. (0 ms total)\n",
    "[  PASSED  ] 3 tests.\n",
    "$ env PYTHONPATH=$(pwd) pytest tests\n",
    "============================= test session starts ==============================\n",
    "platform darwin -- Python 3.7.3+, pytest-4.4.1, py-1.8.0, pluggy-0.9.0\n",
    "rootdir: /Users/yungyuc/hack/code/turgon/spacetime\n",
    "collected 51 items\n",
    "\n",
    "tests/test_celm_selm.py .............................                    [ 56%]\n",
    "tests/test_grid.py ....                                                  [ 64%]\n",
    "tests/test_inviscid_burgers.py ..                                        [ 68%]\n",
    "tests/test_linear_scalar.py ......                                       [ 80%]\n",
    "tests/test_solution.py ..........                                        [100%]\n",
    "\n",
    "========================== 51 passed in 0.38 seconds ===========================\n",
    "```\n",
    "\n",
    "The testing needs to be automatic.  If they weren't, we are introducing an unnecessary factor for human error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Why having test\n",
    "\n",
    "To err is human.  It's possible to be free from mistakes for 20 lines of code, but it is unrealistic to write 1,000 lines of code and expect no error.  There's a time I changed 200 lines of code without running a compiler while typing, at the end when the compiler builds without an error I fell out of my chair.\n",
    "\n",
    "Thus, it's commonplace that programmers write \"experimental code\" during development.  Numerical code is no different.  Compared to other applications, numerical code tends to formulate a full problem for the experiment.  If the code is for a research project, the \"experiemnt\" itself may sometimes be the purpose.\n",
    "\n",
    "For any application, the experimental code isn't much different from a test that will be used to check for regressions.  We may run the tests every time we change the code.  Thus, it's important to make the automatic tests fast.\n",
    "\n",
    "Sensitivity is an equivalently important point for automatic tests.  We want the tests to capture regressions.  But we don't want they to fail with expected change of results and slow down the development.\n",
    "\n",
    "Automatic testing is a simple but important tool to improve coding productivity as well as code quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Google test for C++\n",
    "\n",
    "[Google test](https://github.com/google/googletest) is a popular test framework for C++.  A test framework provides assertions, test discovery, runners, and reports."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "```cpp\n",
    "#include <gtest/gtest.h>\n",
    "\n",
    "#include \"spacetime.hpp\"\n",
    "\n",
    "\n",
    "namespace st = spacetime;\n",
    "\n",
    "TEST(CopyTest, Grid) {\n",
    "\n",
    "    std::shared_ptr<st::Grid> grid=st::Grid::construct(0, 100, 100);\n",
    "    st::Grid copied_grid(*grid);\n",
    "    EXPECT_NE(grid.get(), &copied_grid);\n",
    "\n",
    "}\n",
    "\n",
    "TEST(CopyTest, Solver) {\n",
    "\n",
    "    std::shared_ptr<st::Grid> grid=st::Grid::construct(0, 100, 100);\n",
    "\n",
    "    std::shared_ptr<st::Solver> sol=st::Solver::construct(grid, 1, 1);\n",
    "    std::shared_ptr<st::Solver> cloned_sol=sol->clone();\n",
    "    EXPECT_NE(sol.get(), cloned_sol.get());\n",
    "    EXPECT_EQ(&sol->grid(), &cloned_sol->grid());\n",
    "\n",
    "    std::shared_ptr<st::Solver> cloned_grid_sol=sol->clone(true);\n",
    "    EXPECT_NE(sol.get(), cloned_grid_sol.get());\n",
    "    EXPECT_NE(&sol->grid(), &cloned_grid_sol->grid());\n",
    "\n",
    "}\n",
    "\n",
    "TEST(SolverTest, Celm) {\n",
    "\n",
    "    std::shared_ptr<st::Grid> grid=st::Grid::construct(0, 100, 100);\n",
    "    std::shared_ptr<st::Solver> sol=st::Solver::construct(grid, 1, 1);\n",
    "\n",
    "    st::Celm ce0 = sol->celm(0, false);\n",
    "    st::Celm ce99 = sol->celm(99, false);\n",
    "    EXPECT_FALSE(ce0 == ce99);\n",
    "    EXPECT_TRUE (ce0 != ce99);\n",
    "    EXPECT_TRUE (ce0 <  ce99);\n",
    "    EXPECT_TRUE (ce0 <= ce99);\n",
    "    EXPECT_FALSE(ce0 >  ce99);\n",
    "    EXPECT_FALSE(ce0 >= ce99);\n",
    "\n",
    "}\n",
    "\n",
    "int main(int argc, char **argv) {\n",
    "    ::testing::InitGoogleTest(&argc, argv);\n",
    "    return RUN_ALL_TESTS();\n",
    "}\n",
    "\n",
    "/* vim: set et ts=4 sw=4: */\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Python tests\n",
    "\n",
    "Python standard library has a unit-test framework: https://docs.python.org/3/library/unittest.html .  It serves the same purpose for Python as Google-test for C++.  This sort of tests is called unit tests because they test the smallest unit of constructs in a system.  Since our requirements of the automatic testing is speed and sensitivity, it usually becomes equivalent to unit tests.\n",
    "\n",
    "There are many other types of testing.  General software quality assurance is a bigger subject, and relate less directly to code development.  It is not discussed here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "```python\n",
    "import unittest\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import libst\n",
    "\n",
    "\n",
    "class GridTC(unittest.TestCase):\n",
    "\n",
    "    def setUp(self):\n",
    "\n",
    "        self.grid10 = libst.Grid(xmin=0.0, xmax=10.0, nelm=10)\n",
    "\n",
    "    def test_construction(self):\n",
    "\n",
    "        with self.assertRaisesRegex(\n",
    "            ValueError,\n",
    "            \"Grid::Grid\\(xmin=0, xmax=10, ncelm=0\\) invalid argument: \"\n",
    "            \"ncelm smaller than 1\",\n",
    "        ):\n",
    "            libst.Grid(0, 10, 0)\n",
    "\n",
    "        with self.assertRaisesRegex(\n",
    "            ValueError,\n",
    "            \"Grid::Grid\\(xmin=10, xmax=10, ncelm=10\\) invalid arguments: \"\n",
    "            \"xmin >= xmax\",\n",
    "        ):\n",
    "            libst.Grid(10, 10, 10)\n",
    "\n",
    "        with self.assertRaisesRegex(\n",
    "            ValueError,\n",
    "            \"Grid::Grid\\(xmin=11, xmax=10, ncelm=10\\) invalid arguments: \"\n",
    "            \"xmin >= xmax\",\n",
    "        ):\n",
    "            libst.Grid(11, 10, 10)\n",
    "\n",
    "        # Simply test for passing.\n",
    "        libst.Grid(xloc=np.arange(2) * 0.1)\n",
    "\n",
    "        for s in [0, 1]:\n",
    "            with self.assertRaisesRegex(\n",
    "                ValueError,\n",
    "                \"Grid::init_from_array\\(xloc\\) invalid arguments: \"\n",
    "                \"xloc.size\\(\\)=%d smaller than 2\" % s\n",
    "            ):\n",
    "                libst.Grid(xloc=np.arange(s) * 0.1)\n",
    "\n",
    "        with self.assertRaisesRegex(\n",
    "            ValueError,\n",
    "            \"Grid::init_from_array\\(xloc\\) invalid arguments: \"\n",
    "            \"xloc\\[0\\]=1 >= xloc\\[1\\]=0.9\"\n",
    "        ):\n",
    "            libst.Grid(xloc=np.arange(10, -1, -1) * 0.1)\n",
    "\n",
    "    def test_xcoord(self):\n",
    "\n",
    "        nx = (self.grid10.ncelm + self.grid10.BOUND_COUNT)*2 + 1\n",
    "        golden_x = np.arange(0.0, 10.1, 0.5)\n",
    "        golden_front = golden_x[0] - golden_x[self.grid10.BOUND_COUNT:0:-1]\n",
    "        golden_back = golden_x[-1] - golden_x[-2:-self.grid10.BOUND_COUNT-2:-1]\n",
    "        golden_back += golden_x[-1]\n",
    "        golden_x = np.hstack([golden_front, golden_x, golden_back])\n",
    "\n",
    "        self.assertEqual(nx, len(self.grid10.xcoord))\n",
    "        self.assertEqual(golden_x.tolist(), self.grid10.xcoord.tolist())\n",
    "        self.grid10.xcoord.fill(10)\n",
    "        self.assertEqual([10]*nx, self.grid10.xcoord.tolist())\n",
    "\n",
    "    def test_number(self):\n",
    "\n",
    "        self.assertEqual(10, self.grid10.ncelm)\n",
    "        self.assertEqual(11, self.grid10.nselm)\n",
    "\n",
    "    def test_str(self):\n",
    "\n",
    "        self.assertEqual(\"Grid(xmin=0, xmax=10, ncelm=10)\",\n",
    "                         str(self.grid10))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Wrap to Python: pybind11\n",
    "\n",
    "A numerical software system is hybrid in language.  C++ is used in the low level for speed and architecture.  Python or another scripting language is in the high level for easy customization.  If users have the source code, they have the option to change the software at any level, but most of the time they would like to stay at the high-level scripting layer that we provide as the user interface.\n",
    "\n",
    "The high-level scripting layer will be also useful for testing.  But the first step is to make the low-level C++ available to Python.  Here comes pybind11.  It is a header-only library to expose C++ types in Python, and vice versa.  We primarily use it for wrapping C++ to Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Here is an example demonstrating how pybind11 works.  We rotate a vector in the 2-dimensional Cartesian coordinate system by an angle.  Let $\\mathbf{v}$ be the original vector, $\\theta$ the rotation angle, and $\\mathbf{v}'$ the rotated vector.  The formula for the rotation is simple:\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathbf{v}' = \\left( \\begin{array}{cc}\n",
    "  \\cos\\theta & -\\sin\\theta \\\\\n",
    "  \\sin\\theta & \\cos\\theta\n",
    "\\end{array} \\right) \\mathbf{v}\n",
    "\\end{align*}\n",
    "\n",
    "The formula can be easily turned into any language.  Since we are showing pybind11, it is implemented in C++ and wrapped to Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    require(['notebook/js/codecell'], function(cc) {\n",
       "        cc.CodeCell.options_default.highlight_modes['magic_text/x-c++src'] =\n",
       "            {reg: [/^\\s*%%pybind11/]};\n",
       "    });\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    .cm-s-ipython span.cm-variable-3 {\n",
       "        color: #208ffb;\n",
       "        font-weight: bold;\n",
       "    }\n",
       "    </style>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this is a magic from https://github.com/aldanor/ipybind\n",
    "%load_ext ipybind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%pybind11\n",
    "\n",
    "#include <pybind11/pybind11.h>\n",
    "\n",
    "#include <cmath>\n",
    "#include <tuple>\n",
    "\n",
    "std::tuple<double, double> rotate(\n",
    "    std::tuple<double, double> const & vec\n",
    "  , double rad\n",
    ")\n",
    "{\n",
    "\n",
    "    const double cth = cos(rad);\n",
    "    const double sth = sin(rad);\n",
    "\n",
    "    return std::tuple<double, double>(\n",
    "        std::get<0>(vec) * cth - std::get<1>(vec) * sth\n",
    "      , std::get<0>(vec) * sth + std::get<1>(vec) * cth);\n",
    "\n",
    "}\n",
    "\n",
    "PYBIND11_MODULE(_vector, mod)\n",
    "{\n",
    "\n",
    "    mod.doc() = \"example C extension module\";\n",
    "\n",
    "    mod.def(\"rotate\", &rotate, \"vector rotation\");\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7071067811865476, 0.7071067811865475)\n",
      "(6.123233995736766e-17, 1.0)\n",
      "(-1.0, 1.2246467991473532e-16)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(rotate((1,0), np.pi/4))\n",
    "print(rotate((1,0), np.pi/2))\n",
    "print(rotate((1,0), np.pi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Continuous integration\n",
    "\n",
    "Continuous integration (CI )is a practice that each developer in a team integrates the individual work into the shared mainstream regularly and frequently.  Thus, the chance for the developers to step on each other's toes is reduced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Here is a simple example.  Assume a developer, Abby, wrote the rotate function:\n",
    "\n",
    "```cpp\n",
    "// vector before angle\n",
    "std::tuple<double, double> rotate(std::tuple<double, double> const & vec, double rad);\n",
    "```\n",
    "\n",
    "But another developer, Bob, assumed another signature:\n",
    "\n",
    "```cpp\n",
    "// angle before vector\n",
    "std::tuple<double, double> rotate(double rad, std::tuple<double, double> const & vec);\n",
    "```\n",
    "\n",
    "When they merge their branches, it is obvious that their code won't work together.  Because the difference in signature, the discrepency is likely to be detected when they try to build the merged source code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "But oftentimes, compiler cannot tell the discrepency.  It can only be detected during runtime.\n",
    "\n",
    "```cpp\n",
    "// the angle is in radian\n",
    "std::tuple<double, double> rotate(std::tuple<double, double> const & vec, double rad);\n",
    "\n",
    "int main(int argc, char ** argv)\n",
    "{\n",
    "    std::tuple<double, double> vec = get_vector();\n",
    "    double deg = get_angle();\n",
    "    // the angle is in degree\n",
    "    std::tuple<double, double> ret = rotate(vec, deg);\n",
    "    return 0;\n",
    "}\n",
    "```\n",
    "\n",
    "If the function assumes the angle to be in radian but the caller uses the wrong unit which is degree, we will need a test to detect the error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## CI service\n",
    "\n",
    "Continuous integration (CI) is tightly coupled with a version control system.  Recall bisection:\n",
    "\n",
    "<img src=\"bisection.png\" style=\"width: 90%; text-align: center;\">\n",
    "\n",
    "For bisection to work, we need to know the test results for every change.  There needs to be a CI server to monitor each of the check-ins to the shared repository, build the software, and run necessary tests.\n",
    "\n",
    "[Travis CI](https://travis-ci.com/) is one of such services available for public use.  It has a convenient integration with Github.  It reads a configuration file, named `.travis.yaml`, in your repository's root directory.  When Travis CI detects a change in the repository, it will launch at least one virtual machine to execute the commands in the configuration file.  (Of course, Travis CI is not the only public CI service.)\n",
    "\n",
    "For large-scale software development team, it is commonplace to build their in-house CI system.  It may be built from scratch or by customizing a general system like [Jenkins](https://jenkins.io/).  The in-house system usually will be highly integrated to the internal infrastructure and offer features very specific to the products it serves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Code review\n",
    "\n",
    "Software development takes a lot of communication.  This may be counter-intuitive to non-developers.  In an ideal, entropy free world, there is no cost to transfer information between minds, and collaboration is conducted without friction in communication.\n",
    "\n",
    "In real world, communication doesn't work like that.  To develop useful software, the goal itself must be defined first.  This takes a lot of work and, intuitively, communication.  But after the goal is clarified and defined, we still need to spend a lot of efforts in commucation.\n",
    "\n",
    "You may be curious why?  Let's use our vector example again:\n",
    "\n",
    "```cpp\n",
    "// vector before angle by Abby\n",
    "std::tuple<double, double> rotate(std::tuple<double, double> const & vec, double rad);\n",
    "// angle before vector by Bob\n",
    "std::tuple<double, double> rotate(double rad, std::tuple<double, double> const & vec);\n",
    "```\n",
    "\n",
    "Assume Abby develop her version first.  If she kept that herself, nothing prevents Bob's incompatible version from being written.  But if Abby somehow tells her colleagues her design, Bob may not create the incompatible version in the first place.\n",
    "\n",
    "Code review is an efficient way for Abby to communicate with Bob about her change.  It actually works in two way:\n",
    "\n",
    "1. When Abby develops the function `rotate`, she post a code review and Bob learns from her how `rotate` should work.\n",
    "2. When Bob develops code that uses `rotate`, he posts a code review, and Abby can comment that his version isn't compatible to the existing implementation, and asks Bob to modify.\n",
    "\n",
    "Here is a real-world example for how code review works: https://github.com/QuantStack/xtensor-python/pull/175."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Timing\n",
    "\n",
    "Measurement is the first and most important thing to do for developing high-performance code.\n",
    "\n",
    "There are usually two \"times\" we measure: CPU time and wall time.  The latter is also called elapsed time.  To know how fast a specific code snippet runs, CPU time provides accurate measurement.  It takes into account only the time when the processor is allocated to the process, and isn't mixed with other processes or system calls.\n",
    "\n",
    "But when measuring the performance of the overall system, for which usually everything is taken into account, we may use the wall time.  The wall time is the time that elapses in the real world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Timing command\n",
    "\n",
    "In Linux, you can issue a `bash` command for timing: `time`.  It reports the time spent in the command that is passed to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "real\t0m0.005s\r\n",
      "user\t0m0.001s\r\n",
      "sys\t0m0.002s\r\n"
     ]
    }
   ],
   "source": [
    "!time ls > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "The \"real\" time means the wall time.  The \"user\" time is the CPU time spent in the executable's code.  The \"system\" time is the CPU time spent in the OS calls from the executable.  The total CPU time is the user and system times combined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Linux timing functions\n",
    "\n",
    "In C and C++ programs, we can use the timing functions provided by the [C library](https://www.gnu.org/software/libc/manual/html_node/Date-and-Time.html).  For example, the CPU time may be obtained from:\n",
    "\n",
    "```c\n",
    "clock_t times (struct tms *buffer);\n",
    "```\n",
    "\n",
    "The wall time may be obtained from:\n",
    "\n",
    "```c\n",
    "int gettimeofday (struct timeval *tp, struct timezone *tzp);\n",
    "```\n",
    "\n",
    "Timing is tricky for multi-threading and on an multi-process system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Python timing tool\n",
    "\n",
    "Python has a module `timeit` in its standard library for timing.  By default it uses wall time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 loops, best of 5: 21.7 usec per loop\r\n"
     ]
    }
   ],
   "source": [
    "!python3 -m timeit '\"-\".join(str(n) for n in range(100))'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jupyter provides magics for timing too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.9 s  165 ns per loop (mean  std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# line magic\n",
    "%timeit \"-\".join(str(n) for n in range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.7 s  1.6 s per loop (mean  std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# cell magic\n",
    "\"-\".join(str(n) for n in range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32 s, sys: 1 s, total: 33 s\n",
      "Wall time: 35 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0-1-2-3-4-5-6-7-8-9-10-11-12-13-14-15-16-17-18-19-20-21-22-23-24-25-26-27-28-29-30-31-32-33-34-35-36-37-38-39-40-41-42-43-44-45-46-47-48-49-50-51-52-53-54-55-56-57-58-59-60-61-62-63-64-65-66-67-68-69-70-71-72-73-74-75-76-77-78-79-80-81-82-83-84-85-86-87-88-89-90-91-92-93-94-95-96-97-98-99'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time \"-\".join(str(n) for n in range(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Exercises\n",
    "\n",
    "1. Write a bash shell script to build all of the example programs in the previous lectures.\n",
    "2. Write a Makefile to build all of the example programs in the previous lecture.\n",
    "3. Write a C++ function that calculates the angle (in radians) between two vectors in the 2-dimensional Cartesian coordinate system.  Use pybind11 to wrap it to Python.  Use Python unit-test to check the result is correct.  You may use third-party test runners, e.g., py.test or nosetest.\n",
    "4. Use the package ipybind (https://github.com/aldanor/ipybind) to enable building C++ code in Jupyter notebook.  Repeat problem 3 without the unit tests, but do it in a Jupyter notebook.  Test code should be included in the Jupyter notebook, but the execution can be manual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# References\n",
    "\n",
    "* https://www.gnu.org/software/bash/manual/bash.html\n",
    "* https://www.gnu.org/software/make/manual/make.html\n",
    "* https://pybind11.readthedocs.io/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
